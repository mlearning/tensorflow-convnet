{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<H1 style=\"text-align: center;\"> TensorFlow Tutorial</H1>\n",
    "<H2 style=\"text-align: center;\"> Convolutional Neural Networks</H2>\n",
    "<footer style=\"text-align: center;\"> Kent Yu<br><br>10/21/2016</footer>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "* **Problem** \n",
    "    * Classify RGB 32x32 pixel images across 10 categories\n",
    "    \n",
    "* **Solution**\n",
    "    * Build a relatively small convolutional neural network (CNN) for recognizing images\n",
    "    * A mini version of ImageNet classificaion by Alex  Krizhevsky in UofT in 2012 (1.06 million vs 60 million parameters) (https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-)\n",
    "    \n",
    "* **Implication**\n",
    "    * Provides a template for constructing larger and more sophisticated models\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Structure\n",
    "\n",
    "* Creating the model\n",
    "* Training the model\n",
    "* Evaluating the model\n",
    "* Others\n",
    " * Proprocessing and preparation, e.g. read image files, shuffle, crop and flip the images etc\n",
    " * Reporting and visualzation\n",
    " * Performance tuning, e.g. using multiple GPUs, using async services such as queues\n",
    " * Utility functions, e.g. calculating moving average etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The model graph\n",
    "![tensorboard graph](./cifar_graph.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converlutional Network Illustration\n",
    "<img src=\"./convolutional-network-demo.gif\" width=700/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conv1 Layer\n",
    "* ** Input: 128 X 24 X 24 X 3 **\n",
    "* **Kernel size: 5 (Height) X 5 (Width) X 3 (Channels) X 64 (#of Kernels)**\n",
    "* ** Stride: 1,1,1,1;  Padding: Same **\n",
    "* **Activation: RELU (Retified Linear Unit)**\n",
    "* ** Output: 128 X 24 X 24 X 64 **\n",
    "* ** Technique used: Weight Decay Regularization (to prevent over-fitting) **\n",
    "\n",
    "![tensorboard graph](./Conv1.jpg \"\")\n",
    "\n",
    "```python\n",
    "  # conv1\n",
    "  with tf.variable_scope('conv1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 3, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(bias, name=scope.name)\n",
    "    _activation_summary(conv1)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wegith Decay\n",
    "\n",
    "* With a given cost or error function E(w), and learning rate ETA (η)\n",
    "![tensorboard graph](./WeightDecay.jpg \"\")\n",
    "* The new term **−ηλwi** coming from the regularization causes the weight to decay in proportion to its size.\n",
    "* As a rule of thumb, the more training examples you have, the weaker this term should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pool 1 Layer\n",
    "* ** Input: 128 X 24 X 24 X 64 **\n",
    "\n",
    "* **KSize:  1 (Batch) X 3 (Height) X 3 (Width) X 1 (Channel) **\n",
    "* **Stride: 1 (Batch) X 2 (Height) X 2 (Width) X 1 (Channel) **\n",
    "* **Type: Max**\n",
    "* **Padding: Same**\n",
    "\n",
    "* ** Output: 128 X 12 X 12 X 64 **\n",
    "![tensorboard graph](./Pool1.jpg \"\")\n",
    "\n",
    "```Python\n",
    "  # pool1\n",
    "  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "```                         \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Norm1 Layer\n",
    "\n",
    "* tf.nn.lrn(**pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1'**)\n",
    "* Purpose: to reduce \"lateral inhibition\"\n",
    "* **Accoring to CS231n, LRN is rarely used recently**\n",
    "> Many types of normalization layers have been proposed for use in ConvNet architectures,\n",
    "> ...\n",
    "> ...\n",
    "> However, these layers have since fallen out of favor because in practice their contribution has been shown to be minimal, if any. \n",
    "* What it does\n",
    "![tensorboard graph](./LRN.jpg \"\")\n",
    "\n",
    "```Python\n",
    "  # norm1\n",
    "  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1')\n",
    "```\n",
    "## From ImageNet paper\n",
    "![ensorboard graph](./LocalReponseNormalization.jpg \"\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conv2 Layer\n",
    "* ** Input: 128 X 12 X 12 X 64 **\n",
    "* **Kernel size: 5 (Height) X 5 (Width) X 64 (Channel) X 64 (# of Kernels)**\n",
    "* **Activation: RELU **\n",
    "* ** Output: 128 X 12 X 12 X 64 **\n",
    "![tensorboard graph](./Conv2.jpg \"\")\n",
    "\n",
    "```Python\n",
    " # conv2\n",
    "  with tf.variable_scope('conv2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 64, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(bias, name=scope.name)\n",
    "    _activation_summary(conv2)\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Norm2 Layer\n",
    "\n",
    "* tf.nn.lrn(**conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,name='norm2')**)\n",
    "\n",
    "```Python\n",
    "  # norm2\n",
    "  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "```               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pool 2 Layer\n",
    "* ** Input: 128 X 12 X 12 X 64 **\n",
    "\n",
    "* **KSize:  1 (Batch) X 3 (Height) X 3 (Width) X 1 (Channel) **\n",
    "* **Stride: 1 (Batch) X 2 (Height) X 2 (Width) X 1 (Channel) **\n",
    "* ** Type: max **\n",
    "* **Padding: Same**\n",
    "\n",
    "* ** Output: 128 X 6 X 6 X 64 **\n",
    "![tensorboard graph](./Pool2.jpg \"\")\n",
    "\n",
    "```Python\n",
    "  # pool2\n",
    "  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "```                    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Local 3 Layer\n",
    "\n",
    "* **Input: 128 X 6 X 6 X 64 **\n",
    "* ** Number of Nurons: 384**\n",
    "* ** Output: 128 X 384 **\n",
    "![tensorboard graph](./Local3.jpg \"\")\n",
    "\n",
    "```Python\n",
    "  # local3\n",
    "  with tf.variable_scope('local3') as scope:\n",
    "    # Move everything into depth so we can perform a single matrix multiply.\n",
    "    reshape = tf.reshape(pool2, [FLAGS.batch_size, -1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "    local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local3)\n",
    "```    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###### Local 4 Layer\n",
    "\n",
    "* ** Input: 128 X 384 **\n",
    "* ** Number of Nurons: 192**\n",
    "* ** Output: 128 X 192 **\n",
    "![tensorboard graph](./Local4.jpg \"\")\n",
    "```Python\n",
    "  # local4\n",
    "  with tf.variable_scope('local4') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "    local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local4)\n",
    "```    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Output Layer (Softmax Linear)\n",
    "* **Input:128 X 192 **\n",
    "* **Number of classes: 10**\n",
    "* **Output: 10 (Probability)**\n",
    "![tensorboard graph](./Softmax.jpg \"\")\n",
    "```Python\n",
    "  # softmax, i.e. softmax(WX + b)\n",
    "  with tf.variable_scope('softmax_linear') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
    "                                          stddev=1/192.0, wd=0.0)\n",
    "    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                              tf.constant_initializer(0.0))\n",
    "    softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "    _activation_summary(softmax_linear)\n",
    "```    \n",
    "\n",
    "### **Note: No tf.nn.softmax is applied**\n",
    "\n",
    "* **Compare the above with the output layer in the Deep MNIST for Experts tutorial**\n",
    "```Python\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "    y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lost Function\n",
    "\n",
    "```Python\n",
    "def loss(logits, labels):\n",
    "  \"\"\"Add L2Loss to all the trainable variables.\n",
    "\n",
    "  Add summary for \"Loss\" and \"Loss/avg\".\n",
    "  Args:\n",
    "    logits: Logits from inference().\n",
    "    labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
    "            of shape [batch_size]\n",
    "\n",
    "  Returns:\n",
    "    Loss tensor of type float.\n",
    "  \"\"\"\n",
    "  # Calculate the average cross entropy loss across the batch.\n",
    "  labels = tf.cast(labels, tf.int64)\n",
    "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      logits, labels, name='cross_entropy_per_example')\n",
    "  cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "  tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "  # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "  # decay terms (L2 loss).\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "```  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reduce Mean\n",
    "\n",
    "reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None)\n",
    "input_tensor: The tensor to reduce. Should have numeric type.\n",
    "reduction_indices: The dimensions to reduce. If `None` (the defaut),\n",
    "    reduces all dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "[ 1.5  1.5]\n",
      "[ 1.  2.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xarray =np.array([[1., 1. ] \n",
    "                , [2., 2.]])\n",
    "x = tf.convert_to_tensor(xarray)\n",
    "with tf.Session():\n",
    "    print((tf.reduce_mean(x)).eval() )  # 1.5\n",
    "    print(tf.reduce_mean(x, 0).eval())  # [1.5 , 1.5]\n",
    "    print(tf.reduce_mean(x, 1).eval() ) # [1,\n",
    "                                        #  2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat\n",
      " [[ 0.5  1.5  0.1]\n",
      " [ 2.2  1.3  1.7]] \n",
      "\n",
      "y_hat_softmax\n",
      " [[ 0.227863    0.61939586  0.15274114]\n",
      " [ 0.49674623  0.20196195  0.30129182]]\n",
      "y_hat_softmax_2\n",
      " [ 0.227863    0.61939586  0.15274114] \n",
      " [ 0.49674623  0.20196195  0.30129182] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise to see how tf.nn.softmax_cross_entropy_with_logits \n",
    "# and tf.nn.sparse_softmax_cross_entropy_with_logits works\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Assume y_hat is the calculated result from the tensor graph (Logit)\n",
    "y_hat_array=np.array([[0.5, 1.5, 0.1],[2.2, 1.3, 1.7]])\n",
    "y_hat = tf.convert_to_tensor(y_hat_array)\n",
    "print (\"y_hat\\n\",sess.run(y_hat),'\\n')\n",
    "\n",
    "\n",
    "#Softmax:\n",
    "# For each batch `i` and class `j` we have\n",
    "#      softmax[i, j] = exp(logits[i, j]) / sum_j(exp(logits[i, j]))\n",
    "y_hat_softmax = tf.nn.softmax(y_hat)\n",
    "print (\"y_hat_softmax\\n\",sess.run(y_hat_softmax))\n",
    "\n",
    "e = np.exp(y_hat_array)\n",
    "print (\"y_hat_softmax_2\\n\",e[0] / np.sum(e,axis=1)[0],'\\n',e[1] / np.sum(e,axis=1)[1],'\\n')\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss_per_instance_1= [ 0.4790107   1.19967598]\n",
      "loss_total_1= 0.839343338979 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.convert_to_tensor(np.array([[0.0, 1.0, 0.0],[0.0, 0.0, 1.0]]))\n",
    "#print (\"y_true=\", sess.run(y_true))\n",
    "print (\"\")\n",
    "\n",
    "loss_per_instance_1 = tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true)\n",
    "print (\"loss_per_instance_1=\",sess.run(loss_per_instance_1))\n",
    "# array([ 0.4790107 ,  1.19967598])\n",
    "\n",
    "total_loss_1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true))\n",
    "print (\"loss_total_1=\",sess.run(total_loss_1),'\\n')\n",
    "# 0.83934333897877922\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_per_instance_2= [ 0.4790107   1.19967598]\n",
      "total_loss_2= 0.839343338979 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_per_instance_2 = -tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1])\n",
    "print (\"loss_per_instance_2=\",sess.run(loss_per_instance_2))\n",
    "\n",
    "total_loss_2 = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1]))\n",
    "print (\"total_loss_2=\",sess.run(total_loss_2),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_per_instance_3= [ 0.4790107   1.19967598]\n",
      "loss_total_3= 0.839343338979\n"
     ]
    }
   ],
   "source": [
    "y_true_2 = tf.convert_to_tensor(np.array([1, 2]).astype(np.int64))\n",
    "total_loss_3 = tf.nn.sparse_softmax_cross_entropy_with_logits(y_hat, y_true_2)\n",
    "print (\"loss_per_instance_3=\",sess.run(total_loss_3))\n",
    "\n",
    "total_loss_3 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y_hat, y_true_2))\n",
    "print (\"loss_total_3=\",sess.run(total_loss_3))\n",
    "# 0.83934333897877922"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training steps in MINIST\n",
    "```Python\n",
    "def training(loss, learning_rate):\n",
    "  # Create the gradient descent optimizer with the given learning rate.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  # Create a variable to track the global step.\n",
    "  global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "  # Use the optimizer to apply the gradients that minimize the loss\n",
    "  # (and also increment the global step counter) as a single training step.\n",
    "  train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "  return train_op\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training Operation\n",
    "\n",
    "```Python\n",
    "def train(total_loss, global_step):\n",
    "  \"\"\"Train CIFAR-10 model.\n",
    "\n",
    "  Create an optimizer and apply to all trainable variables. Add moving\n",
    "  average for all trainable variables.\n",
    "\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "    global_step: Integer Variable counting the number of training steps\n",
    "      processed.\n",
    "  Returns:\n",
    "    train_op: op for training.\n",
    "  \"\"\"\n",
    "  # Variables that affect learning rate.\n",
    "  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size\n",
    "  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "  # Decay the learning rate exponentially based on the number of steps.\n",
    "  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                  global_step,\n",
    "                                  decay_steps,\n",
    "                                  LEARNING_RATE_DECAY_FACTOR,\n",
    "                                  staircase=True)\n",
    "  tf.scalar_summary('learning_rate', lr)\n",
    "\n",
    "  # Generate moving averages of all losses and associated summaries.\n",
    "  loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "  # Compute gradients.\n",
    "  with tf.control_dependencies([loss_averages_op]):\n",
    "    opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "  # Apply gradients.\n",
    "  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "  # Add histograms for trainable variables.\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.histogram_summary(var.op.name, var)\n",
    "\n",
    "  # Add histograms for gradients.\n",
    "  for grad, var in grads:\n",
    "    if grad is not None:\n",
    "      tf.histogram_summary(var.op.name + '/gradients', grad)\n",
    "\n",
    "  # Track the moving averages of all trainable variables.\n",
    "  variable_averages = tf.train.ExponentialMovingAverage(\n",
    "      MOVING_AVERAGE_DECAY, global_step)\n",
    "  variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "  with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "\n",
    "  return train_op\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initialization and Training Step\n",
    "\n",
    "```Python\n",
    "def train():\n",
    "  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    # The distorted_inputs function randomly corp, flip and change brightness/contrast of images\n",
    "    images, labels = cifar10.distorted_inputs()\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = cifar10.inference(images)\n",
    "\n",
    "    # Calculate loss.\n",
    "    loss = cifar10.loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "    train_op = cifar10.train(loss, global_step)\n",
    "\n",
    "    # Create a saver.\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Start running operations on the Graph.\n",
    "    sess = tf.Session(config=tf.ConfigProto(\n",
    "        log_device_placement=FLAGS.log_device_placement))\n",
    "    sess.run(init)\n",
    "\n",
    "    # Start the queue runners.\n",
    "    tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph)\n",
    "\n",
    "    for step in xrange(FLAGS.max_steps):\n",
    "      _, loss_value = sess.run([train_op, loss]) # Training\n",
    "     # ...\n",
    "     # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feeding with batch\n",
    "> **Reading data**\n",
    ">\n",
    "> There are three main methods of getting data into a TensorFlow program:\n",
    "\n",
    "> * Feeding: Python code provides the data when running each step.\n",
    "> * Reading from files: an input pipeline reads the data from files at the beginning of a TensorFlow graph.\n",
    "> * Preloaded data: a constant or variable in the TensorFlow graph holds all the data (for small data sets).\n",
    "\n",
    "\n",
    "### Inside cifar10.distorted_inputs()\n",
    "\n",
    "```Python\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "  \"\"\"Construct a queued batch of images and labels.\n",
    "\n",
    "  Args:\n",
    "    image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "    label: 1-D Tensor of type.int32\n",
    "    min_queue_examples: int32, minimum number of samples to retain\n",
    "      in the queue that provides of batches of examples.\n",
    "    batch_size: Number of images per batch.\n",
    "    shuffle: boolean indicating whether to use a shuffling queue.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  # Create a queue that shuffles the examples, and then\n",
    "  # read 'batch_size' images + labels from the example queue.\n",
    "  num_preprocess_threads = 16\n",
    "  if shuffle:\n",
    "    images, label_batch = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size,\n",
    "        min_after_dequeue=min_queue_examples)\n",
    "  else:\n",
    "    images, label_batch = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "  # Display the training images in the visualizer.\n",
    "  tf.image_summary('images', images)\n",
    "\n",
    "  return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
